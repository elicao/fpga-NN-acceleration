{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference - Large\n",
    "\n",
    "This file evaluates the machine learning model on the full MNIST test set.  \n",
    "\n",
    "See the bottom for the code you need to accelerate.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cProfile\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import truncnorm\n",
    "import timeit\n",
    "import multiprocessing as mp\n",
    "#from Network_Class import Network\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "data_path = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_path + \"mnist_test.csv\", delimiter=\",\").values\n",
    "\n",
    "fac = 0.99 / 255\n",
    "test_imgs = np.asfarray(test_data[:, 1:], dtype=np.float32) * fac + 0.01\n",
    "test_imgs = test_imgs.reshape(test_imgs.shape[0], 1, test_imgs.shape[1])\n",
    "\n",
    "test_labels = np.asfarray(test_data[:, :1], dtype=np.float32)\n",
    "\n",
    "lr = np.arange(no_of_different_labels)\n",
    "# transform labels into one hot representation\n",
    "test_labels_one_hot = (lr==test_labels).astype(np.float32)\n",
    "\n",
    "# we don't want zeroes and ones in the labels neither:\n",
    "test_labels_one_hot[test_labels_one_hot==0] = 0.001\n",
    "test_labels_one_hot[test_labels_one_hot==1] = 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model\n",
    "\n",
    "Based on: https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\n",
    "\n",
    "All training (backward propagation) code removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base class\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # computes the output Y of a layer for a given input X\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # backward_propagation removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherit from base class Layer\n",
    "class FCLayer(Layer):\n",
    "    # input_size = number of input neurons\n",
    "    # output_size = number of output neurons\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "    # returns output for a given input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        #self.output = np.linalg.multi_dot([self.input, self.weights]) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    # backward_propagation removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inherit from base class Layer\n",
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.tanh(self.input)\n",
    "        return self.output\n",
    "\n",
    "    # backward_propagation removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhLayer(ActivationLayer):\n",
    "    # static\n",
    "    e = 2.71828182845904523536028747135266249775724709369995\n",
    "    \n",
    "    #http://www.plunk.org/~hatch/rightway.php\n",
    "    #https://math.stackexchange.com/questions/518758/alternative-form-for-sinhx-coshx\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        e = TanhLayer.e\n",
    "        #return np.tanh(x)\n",
    "        #return (1-np.exp(-2 * x))/(1+np.exp(-2 * x))\n",
    "        return (1 - e ** (-2 * x)) / (1 + e ** (-2 * x)) \n",
    "\n",
    "    @staticmethod\n",
    "    def tanh_prime(x):\n",
    "        return 1-TanhLayer.tanh(x)**2\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(TanhLayer,self).__init__(self.tanh, self.tanh_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(): pass\n",
    "def mse_prime(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "        #print(\"Layers: \", self.layers)\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            #print(\"HELLO?\")\n",
    "            # forward propagation\n",
    "            output = input_data[i]\n",
    "            #print(\"Layers:\",self.layers)\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    # backward_propagation removed\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fname):\n",
    "        import pickle\n",
    "        with open(fname, \"br\") as fh:\n",
    "            return pickle.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network.load('network.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mp(net, data, labels, pipe):\n",
    "    \n",
    "    data_len = len(data)\n",
    "    \n",
    "    corrects,wrongs = 0,0\n",
    "    for i in range(data_len):\n",
    "        res = np.array(net.predict(data[i]))\n",
    "        res = res.argmax()\n",
    "        \n",
    "        if res == labels[i]:\n",
    "            corrects += 1\n",
    "        else:\n",
    "            wrongs += 1\n",
    "    \n",
    "    send_data = [corrects, wrongs]\n",
    "    pipe.send(send_data)\n",
    "    \n",
    "    \n",
    "def evaluate(net, data, labels, numProcesses):\n",
    "    corrects, wrongs = 0, 0\n",
    "    \n",
    "    jobs = []\n",
    "    \n",
    "    recv_end, send_end = mp.Pipe()\n",
    "    \n",
    "    for i in range(numProcesses):\n",
    "        jobs.append(mp.Process(target=evaluate_mp, args=(net, data[i], labels[i], send_end)))\n",
    "        jobs[i].start()\n",
    "\n",
    "    for i in range(numProcesses):\n",
    "        recv = recv_end.recv()\n",
    "        corrects += recv[0]\n",
    "        wrongs += recv[1]\n",
    "    send_end.close()\n",
    "    recv_end.close()\n",
    "    \n",
    "    for proc in jobs:\n",
    "        proc.join()\n",
    "   \n",
    "    \n",
    "    return corrects, wrongs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "numProcesses = 2\n",
    "\n",
    "# Split the data and labels into numProcess arrays for each process to use\n",
    "### i.e. for two processes, split the data into two arrays so each process take half of the entire data\n",
    "# Limit of 4 processes for the pynq\n",
    "data1 = []\n",
    "data2 = []\n",
    "data3 = []\n",
    "data4 = []\n",
    "data = [data1,data2,data3,data4]\n",
    "labels1 = []\n",
    "labels2 = []\n",
    "labels3 = []\n",
    "labels4 = []\n",
    "labels = [labels1,labels2,labels3,labels4]\n",
    "\n",
    "num = numProcesses\n",
    "for i in range(num):\n",
    "    data_index1 = int(len(test_imgs)/num)*num - ((num-i)*int(len(test_imgs)/num))\n",
    "    data_index2 = int(len(test_imgs)/num) + i*int(len(test_imgs)/num)\n",
    "    labels_index1 = int(len(test_labels)/num)*num - ((num-i)*int(len(test_labels)/num))\n",
    "    labels_index2 = int(len(test_labels)/num) + i*int(len(test_labels)/num)\n",
    "\n",
    "    if(i==num-1):\n",
    "        data_index2+=1\n",
    "        labels_index2+=1\n",
    "\n",
    "    data[i] = test_imgs[data_index1:data_index2]\n",
    "    labels[i] = test_labels[labels_index1:labels_index2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================\n",
    "# This is the part you need to accelerate:\n",
    "# ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correct:9565\n",
      "Total Incorrect: 434\n",
      "Overall Accruracy: 0.9565956595659566\n",
      "Overall Accruracy (%): 95.6%\n",
      "\n",
      "Run Time: 8.239653669297695 Seconds\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "corrects, wrongs = evaluate(net, data, labels, numProcesses)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print (\"Total Correct:\" + str(corrects))\n",
    "print (\"Total Incorrect: \" + str(wrongs))\n",
    "print(\"Overall Accruracy: \" + str(corrects / ( corrects + wrongs)))\n",
    "print(\"Overall Accruracy (%): \" + str( int( 1000* corrects / ( corrects + wrongs)) / 10) + \"%\")\n",
    "print ()\n",
    "print('Run Time: ' + str(stop - start) + ' Seconds')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For reference, my Pynq takes ~22.4 seconds for the above evaluation.  \n",
    "\n",
    "# Your mission:  Make this run faster, while keeping >95% overall accuracy!\n",
    "\n",
    "### Please refer to the \"Interence_Small\" for details about swapping out individual layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         303 function calls in 8.959 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:416(parent)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
      "        1    0.001    0.001    8.958    8.958 <ipython-input-63-3ae8ffb840f8>:19(evaluate)\n",
      "        1    0.000    0.000    8.958    8.958 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:38(_remove)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:81(add)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:117(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:130(__del__)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:134(_check_closed)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:138(_check_readable)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:173(close)\n",
      "        2    0.000    0.000    8.854    4.427 connection.py:246(recv)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:360(_close)\n",
      "        4    0.001    0.000    8.853    2.213 connection.py:374(_recv)\n",
      "        2    0.000    0.000    8.854    4.427 connection.py:406(_recv_bytes)\n",
      "        1    0.000    0.000    0.001    0.001 connection.py:501(Pipe)\n",
      "        2    0.000    0.000    0.071    0.036 context.py:221(_Popen)\n",
      "        2    0.000    0.000    0.000    0.000 context.py:232(get_context)\n",
      "        2    0.001    0.000    0.071    0.035 context.py:274(_Popen)\n",
      "        1    0.000    0.000    0.001    0.001 context.py:59(Pipe)\n",
      "        8    0.014    0.002    0.015    0.002 iostream.py:195(schedule)\n",
      "        4    0.001    0.000    0.021    0.005 iostream.py:327(flush)\n",
      "        8    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        2    0.000    0.000    0.070    0.035 popen_fork.py:16(__init__)\n",
      "        3    0.000    0.000    0.029    0.010 popen_fork.py:24(poll)\n",
      "        2    0.000    0.000    0.029    0.014 popen_fork.py:43(wait)\n",
      "        2    0.002    0.001    0.049    0.024 popen_fork.py:63(_launch)\n",
      "        2    0.000    0.000    0.029    0.014 process.py:118(join)\n",
      "        2    0.000    0.000    0.000    0.000 process.py:52(_cleanup)\n",
      "        2    0.001    0.000    0.001    0.001 process.py:71(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 process.py:83(<genexpr>)\n",
      "        2    0.001    0.000    0.072    0.036 process.py:95(start)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:139(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:419(detach)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:475(socketpair)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:1062(_wait_for_tstate_lock)\n",
      "       12    0.000    0.000    0.001    0.000 threading.py:1104(is_alive)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:215(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:239(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 threading.py:242(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:248(_release_save)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:251(_acquire_restore)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:254(_is_owned)\n",
      "        3    0.000    0.000    0.004    0.001 threading.py:263(wait)\n",
      "        4    0.000    0.000    0.001    0.000 threading.py:498(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:506(is_set)\n",
      "        4    0.000    0.000    0.004    0.001 threading.py:533(wait)\n",
      "        2    0.001    0.000    0.001    0.001 util.py:151(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 util.py:167(__call__)\n",
      "        2    0.000    0.000    0.021    0.010 util.py:395(_flush_std_streams)\n",
      "        2    0.000    0.000    0.000    0.000 util.py:44(sub_debug)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _imp.lock_held}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _pickle.loads}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _socket.socketpair}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        1    0.000    0.000    8.959    8.959 {built-in method builtins.exec}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.WEXITSTATUS}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.WIFEXITED}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.WIFSIGNALED}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "        2    0.045    0.022    0.045    0.022 {built-in method posix.fork}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method posix.pipe}\n",
      "        4    8.853    2.213    8.853    2.213 {built-in method posix.read}\n",
      "        3    0.029    0.010    0.029    0.010 {built-in method posix.waitpid}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "       24    0.004    0.000    0.004    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'detach' of '_socket.socket' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'setblocking' of '_socket.socket' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'write' of '_io.BytesIO' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cProfile.run(\"evaluate(net,data,labels,numProcesses)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
